## fix bug
7. 依赖任务失败，下游却正常执行了。。。。
9. **插入db的内容不能有单引号**
11. 

## 组件问题


## 改进

5. 用户审批，是否需要设置用户的Hadoop用户
6. running 队列数量

8. 运行失败 显示正常
9. main class 问题
10. 小时任务 恢复
11. bash重跑任务不支持
12. 参数中的choose_time是否需要再加个标识判断是否手动重跑，手动重跑
13. month choose_time
14. 执行命令是否必须存mysql    是否可以存json，避免特殊字符被转义
16. 执行命令 log 输出



## 兼容性
hive spark 参数的兼容性

hive influxdb bug 400 
	select uid,count(*) from hdp_zhuanzhuan_rawdb_global.raw_user where dt = '2018-06-24' group by uid having count(*) >1;

## new feature

set HADOOP_USER_NAME
set jobname

按区间重跑 批量重跑
spark shell 运行，不打jar包

某个时间点master挂了，standby去db里取任务时，导致该job的调度时间已过，怎么办？    --     quartz cluster模式

spark streaming 主要是任务挂了没有报警，然后我们的任务对一致性要求不高，最好有个挂了自动重启的功能

调度平台故障，给正在运行的任务一个状态值，正常后重跑这个状态值的任务    --  对标58dp 等待槽位 中断任务

quartz cluster模式
zzdp定时hive任务发送邮件功能    附件 行数大小限制？  流程是怎样的？
延迟报警        1.启动时间延迟(提示启动时间延迟原因)     2.结束时间延迟       启动延迟之后结束延迟不报警       调度线程？？？？？？
kill job

提供rpc接口
sqoop split by string  --   sqoop本身支持，但会造成数据丢失或者重复的现象，重复的复现比较多，丢失还未发生
数据抽取 支持 tidb

## 前端

离职交接
 


## 废弃功能
UDF管理


0未调度
1等待信号 9等待上游(要不要加？？？)
6等待资源  7解析失败   --  ready queue
2正在执行            --  running queue
3运行成功  4运行失败   
5kill
8暂停


任务状态细化  -- 我整理


